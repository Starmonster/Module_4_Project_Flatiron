{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation System for a new movie streaming service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busines Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) The new service would like an improved recommendation engine for it's current customers to stop the subscription churn\n",
    "#### b) They would like some informed guidance on the type of movie they should be investing in\n",
    "#### c) They would like an interface for new users who can see the kind of movies they might be interested in on the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Reader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collaborative Rec Sys Mod4 Project.ipynb\r\n",
      "Content Based Movie Recomender.ipynb\r\n",
      "Sigmoid recommender alt data set.ipynb\r\n",
      "Surpris Lab mk11 UNBIASED.ipynb\r\n",
      "\u001b[34mml-latest-small\u001b[m\u001b[m\r\n",
      "\u001b[34mtmdb-movie-metadata\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100836 entries, 0 to 100835\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   userId     100836 non-null  int64  \n",
      " 1   movieId    100836 non-null  int64  \n",
      " 2   rating     100836 non-null  float64\n",
      " 3   timestamp  100836 non-null  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./ml-latest-small/ratings.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100836, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       1        1     4.0\n",
       "1       1        3     4.0\n",
       "2       1        6     4.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df.drop(columns=['timestamp'])\n",
    "new_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x11ab271d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = Reader()\n",
    "movies = Dataset.load_from_df(new_df,reader)\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract raw ratings from the dataset\n",
    "raw_ratings = movies.raw_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(raw_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(449, 50, 4.5, None),\n",
       " (274, 8360, 4.0, None),\n",
       " (170, 350, 3.0, None),\n",
       " (414, 308, 4.0, None),\n",
       " (599, 26782, 2.0, None)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_ratings[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to split our ratings data into with 80/20 ratio\n",
    "threshold = int(.8*len(raw_ratings))\n",
    "A_raw_ratings = raw_ratings[:threshold]\n",
    "B_raw_ratings = raw_ratings[threshold:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.raw_ratings = A_raw_ratings #The data is now the A set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import cross_validate\n",
    "from surprise.prediction_algorithms import SVD\n",
    "from surprise.prediction_algorithms import KNNWithMeans, KNNBasic, KNNBaseline\n",
    "from surprise.model_selection import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model using SVD and GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  3.3min finished\n"
     ]
    }
   ],
   "source": [
    "#Now we'll investigate some optimization with GridSearch CV\n",
    "param_grid = {'n_factors':[5,20,100], 'n_epochs':[5,10], 'lr_all':[0.002, 0.005], 'reg_all':[0.02, 0.05, 0.5]}\n",
    "gs_model = GridSearchCV(SVD, param_grid=param_grid, n_jobs=-1, joblib_verbose=3)\n",
    "gs_model.fit(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.8817626184585396, 'mae': 0.6800445780532369}\n",
      "{'rmse': {'n_factors': 5, 'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.02}, 'mae': {'n_factors': 5, 'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.02}}\n"
     ]
    }
   ],
   "source": [
    "print(gs_model.best_score)\n",
    "print(gs_model.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We'll start withh the K-Nearest Neighbors Basic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validate with KNN Basic\n",
    "knn_basic = KNNBasic(sim_options={'name':'pearson', 'user_based':True})\n",
    "cv_knn_basic = cross_validate(knn_basic, movies, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test_rmse', array([0.98011587, 0.99693261, 0.98258366, 0.98413341, 0.98990697]))\n",
      "('test_mae', array([0.7583604 , 0.7684409 , 0.75739477, 0.76228023, 0.76370132]))\n",
      "('fit_time', (0.27557873725891113, 0.2766141891479492, 0.27100324630737305, 0.2721688747406006, 0.27719664573669434))\n",
      "('test_time', (0.7502367496490479, 0.7317829132080078, 0.7414989471435547, 0.7154338359832764, 0.7233130931854248))\n",
      "------------------\n",
      "0.98673450360702\n"
     ]
    }
   ],
   "source": [
    "for i in cv_knn_basic.items():\n",
    "    print(i)\n",
    "print('------------------')\n",
    "print(np.mean(cv_knn_basic['test_rmse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_basic_msd = KNNBasic(sim_options = {'name':'msd', 'user-based':True})\n",
    "cv_knn_basic_msd = cross_validate(knn_basic_msd, movies, n_jobs=-1)                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test_rmse', array([0.96104763, 0.96531222, 0.9572099 , 0.95525152, 0.95782755]))\n",
      "('test_mae', array([0.73794661, 0.73633533, 0.73485218, 0.73270163, 0.73478438]))\n",
      "('fit_time', (0.04732489585876465, 0.06029200553894043, 0.04921293258666992, 0.04758191108703613, 0.04714512825012207))\n",
      "('test_time', (0.7474460601806641, 0.7862210273742676, 0.7575018405914307, 0.7589201927185059, 0.7693719863891602))\n",
      "------------------\n",
      "0.9593297632460018\n"
     ]
    }
   ],
   "source": [
    "for i in cv_knn_basic_msd.items():\n",
    "    print(i)\n",
    "print('------------------')\n",
    "print(np.mean(cv_knn_basic_msd['test_rmse']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we'll try the KNN Baseline algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validate with KNN Baseline (pearson)\n",
    "knn_baseline = KNNBaseline(sim_options={'name': 'pearson', 'user_based':True})\n",
    "cv_knn_baseline = cross_validate(knn_baseline, movies, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test_rmse', array([0.89281547, 0.89508754, 0.88409029, 0.89291285, 0.8839083 ]))\n",
      "('test_mae', array([0.68227875, 0.6820536 , 0.67690286, 0.68230846, 0.67520419]))\n",
      "('fit_time', (0.3129270076751709, 0.3136558532714844, 0.30928683280944824, 0.32314085960388184, 0.306243896484375))\n",
      "('test_time', (0.9831299781799316, 1.0026578903198242, 1.025925874710083, 0.9911098480224609, 0.9960618019104004))\n",
      "-----------------\n",
      "0.8897628923766211\n"
     ]
    }
   ],
   "source": [
    "for i in cv_knn_baseline.items():\n",
    "    print(i)\n",
    "print('-----------------')\n",
    "print(np.mean(cv_knn_baseline['test_rmse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validate with KNN Baseline (mean square difference)\n",
    "knn_baseline_msd = KNNBaseline(sim_options={'name':'msd', 'user_based':True})\n",
    "cv_knn_baseline_msd = cross_validate(knn_baseline_msd, movies, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test_rmse', array([0.88223368, 0.89084087, 0.88731034, 0.88899057, 0.88278093]))\n",
      "('test_mae', array([0.67735611, 0.67624797, 0.67867266, 0.67612274, 0.67520431]))\n",
      "('fit_time', (0.08727693557739258, 0.09384489059448242, 0.09236598014831543, 0.09471821784973145, 0.08886194229125977))\n",
      "('test_time', (1.0900030136108398, 1.0773091316223145, 1.0877001285552979, 1.0861477851867676, 1.0049102306365967))\n",
      "-----------------\n",
      "0.886431277440167\n"
     ]
    }
   ],
   "source": [
    "for i in cv_knn_baseline_msd.items():\n",
    "    print(i)\n",
    "print('-----------------')\n",
    "print(np.mean(cv_knn_baseline_msd['test_rmse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validate with KNN Baseline (pearson_baseline)\n",
    "knn_pearson_baseline = KNNBaseline(sim_options={'name':'pearson_baseline', 'user_based':True})\n",
    "cv_knn_pearson_baseline = cross_validate(knn_pearson_baseline, movies, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test_rmse', array([0.89342926, 0.88956674, 0.89123134, 0.90144818, 0.88875208]))\n",
      "('test_mae', array([0.677976  , 0.67781395, 0.67923366, 0.68740546, 0.67666962]))\n",
      "('fit_time', (0.23274493217468262, 0.23860907554626465, 0.23508787155151367, 0.24143314361572266, 0.22362399101257324))\n",
      "('test_time', (0.9968037605285645, 0.9429259300231934, 0.9261612892150879, 0.9253566265106201, 0.9288880825042725))\n",
      "-----------------\n",
      "0.8928855201446251\n"
     ]
    }
   ],
   "source": [
    "for i in cv_knn_pearson_baseline.items():\n",
    "    print(i)\n",
    "print('-----------------')\n",
    "print(np.mean(cv_knn_pearson_baseline['test_rmse']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And finally we'll try KNN With Means algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validate with KNN With Meanas (Pearson)\n",
    "knn_means = KNNWithMeans(sim_options={'name':'pearson', 'user_based':True})\n",
    "cv_knn_means = cross_validate(knn_means, movies, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test_rmse', array([0.92210312, 0.89967619, 0.90652067, 0.91647664, 0.91363248]))\n",
      "('test_mae', array([0.7005456 , 0.68589484, 0.69125293, 0.69749073, 0.69313747]))\n",
      "('fit_time', (0.28046298027038574, 0.30387187004089355, 0.28382229804992676, 0.2925753593444824, 0.2912709712982178))\n",
      "('test_time', (0.848956823348999, 0.8308649063110352, 0.8434996604919434, 0.8377389907836914, 0.8089640140533447))\n",
      "-----------------\n",
      "0.9116818198811696\n"
     ]
    }
   ],
   "source": [
    "for i in cv_knn_means.items():\n",
    "    print(i)\n",
    "print('-----------------')\n",
    "print(np.mean(cv_knn_means['test_rmse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_means_msd = KNNWithMeans(sim_options={'name':'msd', 'user_based':True})\n",
    "cv_knn_means_msd = cross_validate(knn_means_msd, movies, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test_rmse', array([0.90034021, 0.91509941, 0.9159398 , 0.90839119, 0.90073476]))\n",
      "('test_mae', array([0.68564663, 0.69902919, 0.69775548, 0.69065748, 0.69109206]))\n",
      "('fit_time', (0.05832219123840332, 0.06077003479003906, 0.07342219352722168, 0.05553388595581055, 0.061615943908691406))\n",
      "('test_time', (0.8798611164093018, 0.8598320484161377, 0.8623948097229004, 0.8658139705657959, 0.8569252490997314))\n",
      "-----------------\n",
      "0.9081010734566288\n"
     ]
    }
   ],
   "source": [
    "for i in cv_knn_means_msd.items():\n",
    "    print(i)\n",
    "print('-----------------')\n",
    "print(np.mean(cv_knn_means_msd['test_rmse']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Best Algorithm with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best model above was KNN Baseline with Mean Squared Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  3.2min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_factors':[5,20,100], 'n_epochs':[5,10], 'lr_all':[0.002, 0.005], 'reg_all':[0.02, 0.05, 0.5]}\n",
    "knn_gs = GridSearchCV(KNNBaseline, param_grid=param_grid, n_jobs=-1, joblib_verbose=3)\n",
    "knn_gs.fit(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.8838203956764012, 'mae': 0.6749265261385646}\n",
      "{'rmse': {'n_factors': 5, 'n_epochs': 5, 'lr_all': 0.002, 'reg_all': 0.02}, 'mae': {'n_factors': 5, 'n_epochs': 5, 'lr_all': 0.002, 'reg_all': 0.02}}\n"
     ]
    }
   ],
   "source": [
    "print(knn_gs.best_score)\n",
    "print(knn_gs.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inintial SVD model stayed at the top of the performance list so we will use that to fit test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create our high performance algorithm\n",
    "our_algo = gs_model.best_estimator['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x11dcc5b70>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Retrain on the whole set A\n",
    "trainset = movies.build_full_trainset()\n",
    "our_algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biased accuract on A  RMSE: 0.8416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8415655196781596"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the BIASED Accuracy on A\n",
    "predictions = our_algo.test(trainset.build_testset())\n",
    "print('Biased accuract on A', end='  ')\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbiased accuracy on B, RMSE: 0.8834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8834117006142889"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the UNBIASED Accuract on B\n",
    "testset = movies.construct_testset(B_raw_ratings) #testset is now the set B\n",
    "predictions = our_algo.test(testset)\n",
    "print('Unbiased accuracy on B,', end=' ')\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
